\chapter*{Avant-propos}

Ce mémoire est formé de deux articles qui constituent le fil conducteur de mon activité sur CMS depuis mon arrivée dans cette collaboration en 2005. 
Le premier, en cours de finalisation avant soumission au Journal of Instrumentation, décrit l'algorithme de reconstruction du flux de particules (PF).
Le second, publié au début de l'année 2014 dans le Journal of High Energy Physics, annonce la première mise en évidence du couplage du boson de Higgs à la matière, dans le canal de désintégration $H \rightarrow \tau \tau$. 
Afin de me consacrer à ces deux sujets qui me sont particulièrement chers, 
je ne parlerai pas des recherches de particules supersymétriques auxquelles j'ai consacré deux ans
ni de la découverte du boson de Higgs à laquelle j'ai contribué dans le canal $H \rightarrow ZZ \rightarrow$~4 leptons. 
Je ferai également l'impasse sur mon activité actuelle, qui s'inscrit le long de cette ligne directrice: études prospectives pour les futurs collisionneurs circulaires notamment dans le secteur du Higgs, développement d'une simulation rapide de détecteurs basés sur le PF, 
création d'une équipe $H \rightarrow \tau \tau$ à Lyon pour l'analyse des données du Run II du LHC.
Enfin, je ne couvrirai pas mes responsabilités et contributions plus techniques comme par exemple la constitution de l'équipe d'analyse du groupe CERN de CMS, la création et la maintenance d'outils de computing et d'analyse utilisés par des dizaines de physiciens dans plusieurs expériences, et la coordination du groupe de développement logiciel pour les expériences du FCC (Futurs Collisionneurs Circulaires). 

La reconstruction du flux de particules (PF) consiste à combiner les informations de tous les détecteurs de l'expérience pour reconstruire et identifier de manière optimale chacune des particules stables de l'état final de la collision: electrons, muons, photons, hadrons chargés, et hadrons neutres. 
Cette technique, couronnée de succès au LEP et notamment dans ALEPH, 
est maintenant à la base de la conception des futurs détecteurs généralistes pour la physique des hautes énergies 
pour l'ILC, CLIC, et le FCC. 
Cependant, au milieu des années 2000, seulement quelques années avant le démarrage du LHC, 
personne n'était encore parvenu à faire fonctionner cette technique en collisionneur hadronique.
Patrick Janot avait déjà lancé quelques études préliminaires dans CMS et réalisé que ce détecteur avait les caractéristiques nécessaires pour cette technique de reconstruction, 
et j'ai décidé de le rejoindre pour placer les premières pierres de l'algorithme de PF de CMS.
Durant la première année, j'ai créé l'algorithme de collecte ({\em
  clustering}) permettant une mesure optimale des dépôts d'énergie
dans tous les calorimètres, puis mis en place la première version du PF permettant la reconstruction des photons, des hadrons chargés et des hadrons neutres, 
démontrant d'excellentes performances pour les désintégrations hadroniques du $\tau$, un système relativement simple.
Ces études ont mené à la création du groupe ``PF et identification des $\tau$'', dont Rick Cavanaugh et Patrick Janot ont pris la direction. 
Pour ma part, après avoir créé l'infrastructure logicielle pour le PF dans CMS et plus de 50 000 lignes de code, j'ai pris la responsabilité de ce logiciel, et encadré avec Patrick Janot une dizaine de personnes lors du développement d'améliorations et d'extensions, notamment Michele Pioppi (traces des particules chargées), Florian Beaudette et Daniele Benedetti (électrons), Matt Nguyen (muons), Maxime Gouzevitch (interactions nucléaires et conversions dans le trajectographe), Michel Della Negra (reconstruction des hadrons chargés de haute énergie), et Alexandre Zabi (gerbes hadroniques dans le HCAL).
En 2008, j'ai pris avec Simone Gennai la tête du groupe ``PF et identification des $\tau$'', alors que Patrick me remplaçait en tant que responsable du logiciel pour mettre la dernière main à notre algorithme. 
C'est à la fin de cette année-là que je pus enfin présenter nos résultats lors d'un séminaire au département de physique du CERN: une très nette amélioration des performances globales de CMS, par exemple d'un facteur deux pour la résolution en énergie des jets. 
%À cette occasion un célèbre physicien du CERN me fit le commentaire suivant: 
%``Vous comptez vraiment utiliser ça au démarrage du LHC? eh bien je ne me fais pas de souci pour ATLAS...''
%Compte tenu du fait que nous étions en train de révolutionner la reconstruction des objets de physique de CMS à un an du démarrage, son inquiétude était tout à fait légitime, et était en fait partagée par la grande majorité des membres de la collaboration. 
Au démarrage du LHC, j'ai coordonné et encadré le groupe pour une série d'analyses qui permirent de valider progressivement sur les données tous les aspects du PF: reconstruction des photons et des hadrons chargés avec les événements de diffusion proton-proton inélastiques, reconstruction des particules dans les jets et de l'énergie transverse manquante avec les premiers événements multijet, et finalement validation de la reconstruction et de l'identification des leptons avec l'accumulation d'un échantillon suffisant de bosons W et Z. 
Pour s'assurer du bon fonctionnement de notre algorithme, nous dûmes empiéter sur le domaine des autres groupes ``objets'' de CMS, notamment Jet/MET, e/gamma, et muons, qui n'avaient pas encore adopté le PF et focalisaient leurs efforts sur les techniques de reconstruction traditionnelles. Il nous fallut gagner de haute lutte le droit d'utiliser les jets et les leptons présents dans les données collectées par CMS ainsi que celui de publier nos résultats -- du moins en partie et seulement dans des notes publiques. 
Par la suite, dès 2010, tous les groupes ``objets'' adoptèrent le PF comme méthode standard, et le groupe ``PF et identification des $\tau$'' put être dissout. 
Il nous fallut cependant attendre la publication d'un premier article par chacun des groupes ``objets'' avant de pouvoir proposer en 2014 l'article de référence sur le PF présenté en première partie dans ce mémoire. 
Je pris la responsabilité de la rédaction de cet article avec Patrick Janot et Jan Steggemann, 
et je proposai d'impliquer fortement les cinq groupes ``objets''. 
Mener à bien ce projet nous prit deux ans, durant lesquels j'eus à négocier avec chacun des groupes ``objets'' le contenu scientifique de l'article, à mener et superviser l'analyse, et à gérer la revue interne à la collaboration. 

L'étude de la désintégration du boson de Higgs en $\tau$ est un sujet qui m'intéresse depuis longtemps. 
À l'origine, c'est pour découvrir le boson de Higgs au LHC que je décidai en 2005 de quitter la physique hadronique après une thèse sur la polarisation des gluons dans le nucléon avec l'expérience COMPASS.
J'avais en effet réalisé que je m'étais contenté durant cette thèse d'étudier un système, le nucléon, plutôt qu'une théorie fondamentale. 
Après avoir vu le PF en action sur les désintégration hadroniques du $\tau$, 
je me mis à la recherche d'une analyse qui puisse servir de banc de test à cette technique de reconstruction. 
La canal $H \to \tau \tau$ m'apparut vite comme le candidat idéal. 
D'abord, sur collisionneur hadronique, ce mode de désintégration est de loin le plus adapté à l'étude du couplage entre le boson de Higgs et la matière. 
Ensuite, l'état final, particulièrement complexe, fait intervenir tous les objets de physique obtenus à partir du flux de particules reconstruites.
En effet, chacun des deux $\tau$ se désintègre de manière hadronique en quelques hadrons bien collimatés, 
ou de manière leptonique en électron ou en muon, tout en émettant un ou deux neutrino révélés par de l'énergie transverse manquante. 
En plus de ces produits de désintégration, réclamer des jets dans l'état final permet d'augmenter le rapport signal sur bruit, en ciblant notamment la production du boson de Higgs par fusion de bosons vecteurs qui donne lieu à deux quarks de rapidité très différente, une signature tout à fait caractéristique. 
À mon entrée au CNRS en 2007, je lançai avec le soutien d'Yves Sirois une équipe $H \to \tau \tau$ au sein du groupe CMS de l'École Polytechnique de Palaiseau. 
Yves maintint et développa cette équipe bien après mon départ pour le CERN, et elle contribua fortement à la mise en évidence de ce mode de désintégration. 
En 2011, je créai l'équipe $H \to \tau \tau$ du groupe CERN. 
Je parvins à y attirer cinq fellows recherche et un doctorant et, au bout de deux ans, nous prîmes la position dominante sur cette analyse hautement prioritaire dans CMS.
Je devins alors avec Jan Steggemann l'éditeur de l'article présenté dans ce mémoire, 
et de facto le coordinateur de cette analyse dans CMS. 
À cette époque, cinq grands groupes participaient à l'analyse principale: le CERN, l'École Polytechnique, Imperial College, le MIT, et l'Université du Wisconsin.
En plus de mener l'analyse pour le groupe CERN, mes tâches les plus ardues furent de rassembler ces groupes et de les aider à converger vers une stratégie d'analyse commune tout en en limitant l'intense compétition interne, 
et de m'assurer de la pertinence et de l'exactitude de dizaines d'analyses indépendantes.
Dès le début de 2013, nous pûmes révéler aux rencontres de Moriond 
un excès d'évévenements important, correspondant à 2.94 déviations standard, qui constituait la première indication d'une possible désintégration du boson de Higgs en paire de $\tau$. 
Après une réoptimisation complète de l'analyse, nous publiâmes un an plus tard le résultat final dans l'article présenté dans ce mémoire, avant que je quitte le CERN pour rejoindre Lyon.  

Ce travail est évidemment un travail d'équipe, et je souhaite profiter de cet avant-propos pour remercier les personnes avec qui j'ai eu tant plaisir à travailler.  
Je remercie tous les membres du groupe PF, qui ont fait de ce projet un tel succès et avec qui j'ai passé mes plus belles années dans CMS.  
Je tiens également à remercier tous les membres de l'équipe $H \to \tau \tau$ du CERN, et notamment Jan Steggemann, qui m'a fait le grand plaisir d'accepter de prendre en charge l'édition d'une partie de chacun des deux articles présentés ici.  
Je remercie Yves Sirois et tous les membres de l'équipe CMS du laboratoire Leprince-Ringuet pour leur soutien, 
ainsi que Guy Chanfray, Patrice Verdier, et toute l'équipe CMS de l'IPNL pour leur soutien et l'excellent accueil qu'ils m'ont réservé à Lyon. 
Enfin, je remercie tout particulièrement mon cher ami Patrick Janot, pour tout ce qu'il m'a apporté au cours de ces dix dernières années. Nos routes ne se sépareront pas. 
